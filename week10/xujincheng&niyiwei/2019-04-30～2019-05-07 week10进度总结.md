## 2019-04-30～2019-05-7 week10进度总结
###  苏昭帆

1.对语音情感识别的深度学习实现算法进行了调研，找到了一些paper以及代码

2.复现了一篇使用PCA进行数据降维、之后使用k-折结合svm支持向量机的paper，使用科大中文语音数据集进行训练与测试，
测试结果最好可达到77.8%，原作者使用柏林语音数据集，测试效果稍好一些。

3.作者后面一小部分使用KNN优化那部分，虽然写完了代码，但是没有运行成功，因为配置有些问题没来得及解决。作者使用这个算法优化之后准确率提高到85%以上。

[paper&code](https://github.com/Zhaofan-Su/SpeechEmotionRecognition-papers-codes)
### 刘娅璇/刘岳涵  

1. 调研：找到了开源的中文聊天语料，且已进行系统化整理，与微博数据集相比，更规范，可直接使用，链接：https://github.com/codemayq/chinese_chatbot_corpus

2. 使用python自带的ChatterBot效果很差：回答问题的正确率远低于50%，对于闲聊类问题可以回答正确几个，对于知识类的问题不能给出正确的回答。

3. 学习seq2seq模型：CSDN https://blog.csdn.net/qq_35495233/article/details/86611852#13__42

   论文 [http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks)

   在github找到相关demo，但还没有运行，链接：https://github.com/qhduan/Seq2Seq_Chatbot_QA
   
### 邹笑寒

1. 使用 [Opensmile](https://github.com/naxingyu/opensmile) 提取 [IS10_paraling](https://github.com/naxingyu/opensmile/blob/master/config/IS10_paraling.conf) 特征（2010 年国际语音挑战赛特征集合，包含 1582 个特征），然后 PCA 降维，MLP 的准确率在 80% 以上，SVM 的准确率在 70% 以上（当然如果我的代码有问题就另说了...）。

	PCA 降维对准确率的提高不是特别大，所以主要应该是特征的问题。
	
	还没有对 LSTM 和 CNN 进行实验，把特征输入神经网络的部分还没有处理好。
	
	代码整理好后将更新在[这里](https://github.com/Renovamen/Speech-Emotion-Recognition)。


2. 整理了一些带代码的论文：[Papers with code](https://github.com/Renovamen/Speech-Emotion-Recognition/tree/Survey)

3. 未来计划：
	- 在 LSTM 和 CNN 上进行实验
	- 尝试别的特征集，如 [IS09_emotion](https://github.com/naxingyu/opensmile/blob/master/config/IS09_emotion.conf) 等

### 郭辉
1. 找到中文电影/电视剧短音频的少量数据

   地址：<https://github.com/a237072751/Speech_Emotion_Recognition/tree/master/speech/rawdata>

2. 查阅资料、阅读论文、查阅相关代码

   论文+代码地址：<https://github.com/XLab-Tongji/SemanticAnalysisProgress/blob/master/week10/guohui/代码%2B论文.md>

3. 对现有代码进行修改：LSTM、GRU、Bilstm、BiGRU实现

   数据集：casia简略版（1200音频）

   结果：     LSTM: 	val_acc > 0.72500

   ​		Bilstm:	val_acc > 0.72917

   地址：<https://github.com/guohui15661353950/audio-data/tree/master/speech_emotion_recognition>

   （不确定代码是否正确）


### 杨慧宇/刘雨
实验：针对无法在embeddings层找到对应向量的字符，寻找jieba分词时细化粒度的方法。现有问题暂时解决了，但更好的解决方法还待寻找。




