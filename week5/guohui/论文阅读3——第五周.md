##Emotion Recognition from Human Speech Using Temporal Information and Deep Learning

###Abstract

* 传统方法：致力于开发良好的特征表示——在这些特征中正确地使用重要的时间信息的工作较少
* 结合已知可用于情感识别的特征和深度神经网络，以在识别情绪状态时利用时间信息。
* 数据集：EMO-DB    识别率：88.9%



###Introduction

* 经典语音情感识别系统：特征提取阶段➡️分类阶段
  * 提取与语音波形中携带的情绪状态相关的关键特征
    * [1]：6373个特征，主要来自具有滑动窗口的短时波形段。
    * Eyben [2]：GeMAPS参数集由62个特征组成，扩展的GeMAPS由88个特征组成，作为评估未来研究的基准。
    * 这些特征与静态模式分类器（如支持向量机（SVM））相结合，可以显示出相当好的性能。
* 传统方法的局限：对于提取的特征如何随时间变化的工作较少
  * 常用方法：使用语音特征向量的序列和平均向量的标准偏差来产生到静态分类器的输入向量
    * 局限：可能导致用于情绪识别的关键时间信息的丢失（例：特征向量的时间反转版本与原始特征向量相同的标准偏差，但它们不一定对应于相同的情绪）
  * 改进：将明确的时间特征附加到输入响亮（例如浊音和清音语音持续时间的平均值和标准差，伪音节率pseudo-syllable rate等）
    * 局限：未能传达所有关键时间信息（例如在不同时间传播的各个特征的时间变化的多种模式）
* 深度神经网络的方法：
  * [4,5]卷积神经网络（CNN）：在语音识别中有效提取高级表示
  * [6]长短期记忆（LSTM）模型：用于序列分类
  * [7]DNN的端到端方法：原始语音波形被直接用作输入以构建学习特征提取和分类的模型。
    * 局限：
      * 未能在情感识别领域建立的有用特征
      * 需要较大的网络规模（模型需要共同学习特征提取和分类，因此需要大量数据才能获得良好的性能）

* **EmNet**模型：
  * 使用对情感识别有用的共同特征而不消除它们的时间信息
  * DNN提取特征的时间模式的更高级层次的representation并将它们与相应的情绪状态相关联。



###Proposed EmNet Model

多个处理阶段：特征提取➡️特征归一化➡️局部卷积的CNN层➡️全局卷积的CNN层➡️前馈层的LSTM层

![](https://github.com/guohui15661353950/pictures/blob/master/屏幕快照%202019-04-02%20上午10.41.14.png?raw=true)

####2.1. Feature extraction

* 在eGeMAPS的88个特征中使用20个特征：

  过零率zero-crossing rate；对数帧能量log frame energy；帧能量熵frame energy entropy；谱质心spectral centroid；谱扩散spectral spread；谱熵spectral entropy；谱通量spectral flux；频谱滚降spectral roll-off；Mel频率倒谱系数Mel-Frequency Cepstral Coefficients (MFCC) C1 ~ C5；发声概率voicing probability；音调pitch；共振峰带宽formant bandwidth；共振峰增益formant gain；三个谐波能量比three harmonic energy ratios (一次谐波的对数能量与二次和四次谐波的对数能量之比ratio of log energy of the first harmonic to the log energy of the second through fourth harmonics)

* 使用滑动30毫秒汉明窗口每10毫秒从输入语音信号中提取这些特征，以形成20维特征向量的时间序列。

* 为了保留时间信息，这些特征向量直接用作网络的输入，而不是使用它们的均值和标准偏差作为输入。

####2.2. Normalization

* 从相应的说话者获得的均值和标准偏差向量来对特征向量进行标准化（归一化）
* 为了便于后续机器学习阶段使用keras深度学习包，沿着时间轴的特征向量的数量被截断或零填充到512帧（取决于输入语音话语的长度）。生成的特征向量是20x512特征时间表示。

####2.3. Local convolution layer

* 使用1x6滤波器构建局部卷积层，通过该滤波器层，仅对每个特征分量沿时间轴执行卷积运算。
* 将ReLU激活函数应用于每个滤波器的输出以产生64个feature map（根据经验发现64个滤波器产生良好的性能）。
* 对局部卷积层输出上的每个feature map执行pool size为4的max pooling。
* 经过适当的训练，调整各个滤波器以检测 能够改善情绪识别准确性的方向 的重要时间pattern。

####2.4. Global convolution layer

* 根据局部卷积层创建的feature map，设计全局卷积层以使用两个时间帧（对应于80毫秒）跨20维特征的接收区提取更高级别的信息。
  * 滤波器的数量：218，并且ReLU激活函数应用于滤波器的输出。
  * 在pool size为2的每个feature map上应用max pooling，以产生128个特征的时间序列（连续特征之间的时间间隔变为160毫秒）

####2.5. LSTM and feedforward layer

* 全局卷积层的输出由2层LSTM网络处理，每个网络有48个神经元（dropout rate为0.25）

* LSTM层的输出被送到具有softmax激活单元的密集/前馈层，以将输入分类到7种情绪类别之一。

  

###Experiments

####3.1. Database

* 数据库：EMO-DB
  * 它包含535个语音wave文件，由5个女性和5个男性表达的10个短句组成。
  * 每个文件都标有七种情绪中的一种：愤怒，快乐，悲伤，中性，无聊，厌恶和恐惧。

####3.2. Model training and validation

* 使用Leave-One-Speaker-Out（LOSO）交叉验证进行实验（九个说话者：训练集，一个说话者：测试集）
  * 通过更改说话者，获得10个识别率，取平均值。
* 基于EmNet中使用的相同特征集构建了基线静态识别系统（以研究EmNet在合并时态信息方面的有效性）
  * 对于每个语音文件，从20维特征向量的时间序列的平均值和标准偏差获得的40维向量被用作SVM分类器的输入向量。
* 训练：基于ADAM优化器使用keras / theano进行（batch大小：64）
  * 我们在从特定于域的合理搜索范围中逐个探索参数，并在下一个参数的搜索过程中使用最佳或前2个参数值。 
  * 总共评估了98种不同的网络配置，以找到性能最佳的网络配置。

####3.3. Results and discussion

![](https://github.com/guohui15661353950/pictures/blob/master/屏幕快照%202019-04-02%20下午12.08.09.png?raw=true)

* 98次试验中识别率与EmNet自由参数数量的关系，最高性能标记为X。

![](https://github.com/guohui15661353950/pictures/blob/master/屏幕快照%202019-04-02%20下午12.10.43.png?raw=true)

* 不同模型在EMO-DB上的性能：EmNet模型具有相同的20个特征，识别率高达88.9％。
  与baseline相比：51.1％的误差减少率（用到了时间信息，优于先前的现有技术）

![](https://github.com/guohui15661353950/pictures/blob/master/屏幕快照%202019-04-02%20下午12.12.53.png?raw=true)

* 所提出的模型在每个情绪类别与静态baseline SVM相比的有效性
  * 除了happiness之外，EmNet在所有情感类别中的识别错误率降低了50-60％。
  * happiness的错误减少率仅达到约20％。

![](https://github.com/guohui15661353950/pictures/blob/master/屏幕快照%202019-04-02%20下午12.16.27.png?raw=true)

* 混淆矩阵：happiness的错误分类（几乎一半的错误：对anger的错误分类，另一半：对fear的错误分类）
  （红色圆圈）

![](https://github.com/guohui15661353950/pictures/blob/master/屏幕快照%202019-04-02%20下午12.21.04.png?raw=true)

* 在最后一个time step中将t分布式随机邻居嵌入（t-SNE）算法应用于LSTM输出向量而获得的二维情感空间。
  * t-SNE：数据可视化工具——保留原始数据的局部距离及其低维投影。
  * high arousal emotions(happiness, fear 和 anger) 紧密地聚集在一起，价态很难分开——happiness(+) fear 和 anger)(-)
  * 在t-SNE的不同复杂度值在5和80之间观察到类似的趋势(图4复杂度为30)



###Conclusions

* EmNet用于语音的情感识别
  * 已知对情绪识别任务有用的特征提取阶段
  * DNN：通过 根据特征向量的时间序列识别情绪状态 来对未知机制进行建模（其中DNN由两个CNN层（用于局部和全局卷积）和LSTM层组成）

* 建议：收集足够大的新数据集来支持单独的开发集合
* Further remaining works：
  * 扩展功能集（例如eGeMAPS中的88个功能，而不是当前的20个功能）
  * 不同数据库的性能评估
  * 在EMO-DB上对端到端DNN方法的性能评估