##论文阅读——第五周

###《基于神经网络的语音情感识别》

石瑛，胡学钢  2008

####1 引言

人的情感一方面是由外界刺激引起的神经冲动，另一方面也受到自身生理系统的控制和影响。

####2 语音情感研究现状

#####􏱉2.1 语音情感的分类

* 中性（normal）

* 每类情感在活跃程度和积极程度两个方面的细微差别：

  ![](https://github.com/guohui15661353950/pictures/blob/master/屏幕快照%202019-03-31%20上午10.42.06.png?raw=true)

* 有些研究人员还把语音情感从激励(arousal)、愉快(pleasure)和能量(power)三个维度空间来分析研究的。

##### 2.2 建立语情感识别语料库

##### 2.3 语音情感特征提取

* 不同情感下振幅特征的变化：

  * 愤怒和高兴：共振峰($F_{0}​$)平均值、变化范围和方差的提高，能量(振幅)的加强，频谱中高频成分的增加。
  * 悲伤：共振峰($F_{0}$)平均值、变化范围的减小，能量(振幅)的减弱，语速的减慢，频谱中高频成分的降低。
  * 害怕：共振峰($F_{0}$)平均值、变化范围和频谱中高频成分的增加，基频曲线上抖动的加强和语速的加快。
  * 惊讶：很宽的基频变化范围，稍减慢的语速。

  （声学参数随时间的变化曲线也负载了一定的情感信息）

* 5种语音情感的声学特征的统计结果：

  ![](https://github.com/guohui15661353950/pictures/blob/master/屏幕快照%202019-03-31%20上午11.07.15.png?raw=true)

* 相关研究：

  * Petrushin V A：基频$F_{0}$、能量、语速和前三个共振峰$F_{1}$、$F_{2}$和$F_{3}$以及与其对应的3个带宽$Bw_{1}$、$Bw_{2}$和$Bw_{3}$（发现愤怒和悲伤是5种语音情感中最容易识别的两种情感表达方式）
  * Raquel T：韵律特征中选择了基频$F_{0}$、能量和延时，在分类识别中采用了人工神经网络分类器。
  * Nicholson J：韵律特征中提取了能量($P$)和声调($p$)，并结合线性预测系统的特点，在声音特征中提取了12个$LPC$参数($C_{1},C_{2},…,C_{12}$)和$\Delta LPC$参数，然后把每句分为等长的20帧，$F_{v}=\left ( f_{1},f_{2},…,f_{20}\right )$。每帧对应的特征向量是$f_{n}[P_{n},p_{n},C_{n1},C_{n2},…,C_{n12},d_{n}]$，这样每句都能得到300个特征向量。
  * 文[3] (致力于研究情感空间)：韵律特征参数(Prosody Features)，音质特征参数(Quality Features)（实验表明，音质特征参数的使用能有效地提高情感语音的识别率）。
  * 小波变换提取特征参数（为提高识别率）

#####2.4 语音情感识别技术

* 当前比较流行的模式识别方法：

  * 线性判别分类器（LDC）
  * 支持向量机（SVM）
  * 高斯混合模型（GM）
  * 人工神经网络（ANN）
  * 隐马尔可夫模型（HMM）

  （把这些模型基础和其他算法优化结合）

* 相关研究：

  * 文[4]：神经网络由8个子网构成，具有很好的可扩展性
  * 文[10]：采用了3中分类器(最大似然贝叶斯分类法、核回归、K-近邻法)
  * 文[11]：采用K最近邻法识别高兴、愤怒、悲痛和自然4类情感，对基频、能量等相关的基本特征做了比较分析，从中发现了新的特征参数，并在此基础上对k最近邻法做了改进，是该识别系统所需的特征参数和训练数据较少，提高了其可扩展性。
  * 文[12]：线性判别分类、K-近邻法和支持向量机
  * 文[13]：对数频率能量系数和HMM分类方法
  * 文[14]：发现AdaBoosted决策树的方法达到的识别率最好，K-NN、RBF神经网络和SVM也能取得令人满意的效果。



####3 语音情感识别的实现

#####3.1 语音信号的提取

* 分帧、加窗

  分帧的长度一般取20～30ms。帧与帧之间的偏移通常取为帧长的1/2或1/3，即每隔帧长的1/2或1/3进行分帧（本实验在提取MFCC参数时取帧长为20ms(160点)，帧移为10ms(80点)。）

* Mel频率倒谱系数(MFCC)

  是在频谱上采用滤波器组的方法计算出来的，将语音频率划分成一系列三角形的滤波器序列（这组滤波器在频率的美尔(Mel)坐标上是等带宽的）

  MEL频率尺度：更符合人耳的听觉特性。

  Mel频率与实际频率的关系可用下式近似表示:

  $Mel(f)=2595log10(1+f/700)                       \left ( 1 \right )$

  $Mel(f)=1127ln(1+f/700)\left ( 2\right )$

  式中f为频率，单位是Hz。其提取及计算过程如下:

  * 原始语音信号S(n)➡️加重、分帧、加窗➡️每个语音帧的时域信号X(n)➡️离散傅立叶变换(DFT)➡️线性频谱X(k)。

    设语音信号的DFT为：$Xn(k)=\sum_{n=0}^{N-1}x(n)e^{-j2\pi nk/N}     (0\leqslant k\leqslant N)$

    式中x(n)为输入的语音信号，N表示傅立叶变换的点数。

  * 求线性频谱X(k)幅度的平方，即能量谱。通过一组 Mel尺度的三角形滤波器组(Mel滤波器组的频带划分如表3所示)。 

    ![](https://github.com/guohui15661353950/pictures/blob/master/屏幕快照%202019-03-31%20下午5.32.26.png?raw=true)

* 当语音信号的信噪比较低时，单纯用MFCC特征作为静态特征，其识别性能往往不能令人满意。而**瞬态参数(如DeIta参数)则具有明显的环境鲁棒性，将瞬态参数和静态参数相结合可以提高其识别性能**。本文采用
  的瞬态参数是一阶Delta参数，即将前后帧的MFCC系数进行差分运：

  ![](https://github.com/guohui15661353950/pictures/blob/master/屏幕快照%202019-03-31%20下午5.42.24.png?raw=true)

  其中$D_{t}$表示第t个一阶差分倒谱系数，T是为倒谱系数的维数，$\Theta $表示一阶导数的时间差，其值取为1或2，$1\leqslant \theta  \leqslant \Theta $，$C_{t}$表示第t个倒谱系数本文取$\Theta ​$为1。

* （借鉴文献[15]）实验选择16维$MFCC$系数和16维$\Delta MFCC$系数，共计32个语音特征作为特征矢量，用神经网络的方法对录制语料库进行识别实验。

##### 3.2 基于神经网络的语音情感识别模型

* BP神经网络
  * 输入层：32个节点（对应32维语音特征）
  * 隐含层：32个节点
  * 输出层：4个节点（分别对应4种情感状态(去掉中性情感)）
  * 神经网络中各层间的激活函数均选用双曲正切s型函数，以反向传播算法进行训练，学习速率为0.001，训练误差为0.0001，最大迭代步数为500。

#####3.3 实验结果和分析

* 训练数据：2/3，测试数据：1/3

* 输出值的范围：[-1,1]。

* 平均识别率：64.4%







