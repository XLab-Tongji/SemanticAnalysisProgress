# Report of week 5 (2019-03-27~2019-04-02)

## Speech to Text

实现了调用百度和科大讯飞的API进行实时语音识别。

科大讯飞的API需要在后台添加调用方IP（免费版5个），限制次数（免费版一天500次）比较麻烦。

百度API没有什么限制，但似乎效果略低于讯飞。

但两个API的准确率都还是很高的。



## Speech Emotion

Librosa提取特征 + CNN识别

### Datasets

1. [RAVDESS](https://zenodo.org/record/1188976)

   英文，24名演员（12名男性，12名女性）说的大约1500句话，表达了8中不同的情绪：neutral, calm, happy, sad, angry, fearful, disgust, surprised。

2. [SAVEE](http://kahlan.eps.surrey.ac.uk/savee/Download.html)

   英文，4名演员（男性）说的大约500句话，表达了7种不同的情绪：angry, fearful, sad, happy, surprised, neutral, disgust。

   guest2savee welcome!

两个数据集加起来一共1920句。

最终选用了calm, happy, sad, angry, fearful五种情绪，共1200句，其中训练集960句，测试集240句。



### Experiment

实现了简单的CNN模型。用Librosa提取音频MFCC特征，用CNN对上述数据集进行了训练，按8:2的比例划分训练集和测试集，目前准确率为50-55%。

当前问题：

1. 可以对CNN参数、MFCC特征数、采样频率等进行调参以提高准确率，但因为跑一次要大概半小时，调参比较麻烦；

2. 是否对男女性进行标记对结果的影响不大，我对这一点感到困惑；

3. 还没用中文数据集进行测试。



### Survey

收集到的有代码实现的相关论文（包括作者开源代码和别人的复现），都用的神经网络。



[Automatic speech emotion recognition using recurrent neural networks with local attention](https://ieeexplore.ieee.org/abstract/document/7952552)

代码：https://github.com/gogyzzz/localatt_emorecog

RNN



https://github.com/amanbasu/speech-emotion-recognition

LSTM



[Emotion Recognition From Speech With Recurrent Neural Networks](https://arxiv.org/pdf/1701.08071.pdf)

代码：https://github.com/vladimir-chernykh/emotion_recognition

RNN + CTC损失函数

用CTC损失函数，解决了识别一个较长utterance中只有部分帧带有情感的困难。



[3-D Convolutional Recurrent Neural Networks With Attention Model for Speech Emotion Recognition](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8421023)

代码：https://github.com/xuanjihe/speech-emotion-recognition

三维CRNN卷积

用log-Mels的delta1、delta2减少情感无关因素的影响。



[End-to-End Multimodal Emotion Recognition using Deep Neural Networks](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8070966)

代码：https://github.com/tzirakis/Multimodal-Emotion-Recognition

CNN提取特征 + LSTM识别



[Speech emotion recognition using deep neural network and extreme learning machine](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/IS140441.pdf)

代码：https://github.com/eesungkim/Speech_Emotion_Recognition_DNN-ELM

DNN提取特征+ELM识别



[High-level Feature Representation using Recurrent Neural Network for Speech Emotion Recognition](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/Lee-Tashev_Emotion_detection_Interspeech2015.pdf)

RNN+BLSTM提取特征+ELM识别



[Multi-Modal Emotion recognition on IEMOCAP Dataset using Deep Learning](https://arxiv.org/pdf/1804.05788.pdf)

代码：https://github.com/Samarth-Tripathi/IEMOCAP-Emotion-Detection

LSTM+RNN+MLP



[Multimodal Speech Emotion Recognition using Audio and Text](https://arxiv.org/abs/1810.04635)

代码：https://github.com/david-yoon/multimodal-speech-emotion

先语音识别，然后用文本和音频来识别情绪

MDREA (Multimodal Dual Recurrent Encoder with Attention)



[Adversarial Auto-encoders for Speech Based Emotion Recognition](https://guptarah.github.io/myPapers/sahu_gan_IS17.pdf)

代码：https://github.com/eesungkim/Speech_Emotion_Recognition_AAE

AAE （Adversarial Autoencoders，对抗自编码器）